### README

## Описание проекта

Этот проект предназначен для создания и обучения языковой модели с машинным переводом, работающей в режиме чат-бота. Основная задача — обрабатывать запросы на русском языке, предоставлять ответы, обобщения, факты и логические выводы также на русском, при этом сопровождая каждый факт или утверждение ссылками на источники данных. Проект учитывает ежедневно поступающие новостные материалы, что позволяет модели отвечать на запросы с учетом последних новостей.

## Структура проекта

Проект включает несколько этапов обработки данных, чтобы обеспечить качественное обучение модели и её способность обрабатывать и предоставлять актуальные ответы:

1. **Очистка HTML-контента и извлечение ссылок**
2. **Нормализация текста**
3. **Удаление повторяющихся ссылок и лишних пробелов**
4. **Удаление ссылок на изображения**
5. **Сохранение очищенных данных**
6. **Преобразование очищенных данных в формат JSON для дообучения модели**

### Файлы и каталоги

- `config.json`: конфигурационный файл с параметрами проекта, включая пути к директориям с данными.
- `main.py`: основной скрипт для запуска всех этапов обработки данных.
- `/private/tmp/unpacked_files`: исходная директория с WARC-файлами.
- `/Users/aleksandratopalidi/Desktop/HackatonProductAI/cleaned`: целевая директория для сохранения очищенных данных.

## Этапы обработки данных

### 1. Очистка HTML-контента и извлечение ссылок

Используется библиотека `BeautifulSoup` для удаления скриптов, стилей, рекламных блоков и других ненужных элементов из HTML-контента. Извлекаются все ссылки из текста для последующего использования.

### 2. Нормализация текста

Нормализация текста выполняется с использованием библиотеки `unicodedata` для приведения текста к нормальной форме (NFKC), что упрощает дальнейшую обработку.

### 3. Удаление повторяющихся ссылок и лишних пробелов

Используется библиотека `re` для удаления повторяющихся ссылок и лишних пробелов из текста. Это помогает улучшить качество данных для обучения модели.

### 4. Удаление ссылок на изображения

Для удаления ссылок на изображения (формата .jpg) используется регулярное выражение, реализованное с помощью библиотеки `re`.

### 5. Сохранение очищенных данных

Данные сохраняются в структуре директорий по годам, что имитирует поступление данных в режиме реального времени и позволяет модели учитывать новейшую информацию.

### 6. Преобразование очищенных данных в формат JSON

После очистки данные преобразуются в формат JSON для дообучения модели Yandex GPT. Структура JSON-файла включает поля `request` и `response`, которые содержат запросы и ответы соответственно.

Пример структуры JSON:

```json
{
    "request": [
        {
            "role": "system",
            "text": "お知らせ\nTポイントが貯まる『マイナビベアのミニゲーカフェ』開始..."
        },
        {
            "role": "user",
            "text": "iPhoneのインターネット共有をオンにする方法は?"
        }
    ],
    "response": "「設定」の「インターネット共有」を開き、「インターネット共有」をオンにします。出典: [\"https://news.mynavi.jp/article/iphone_kihon-362/\"]"
}
```

## Основной скрипт (main.py)

Скрипт выполняет все этапы обработки данных, описанные выше. Основные функции:

- `clean_html_and_extract_links`: очистка HTML-контента и извлечение ссылок с использованием `BeautifulSoup`.
- `generate_filename`: генерация имени файла на основе URL.
- `normalize_text`: нормализация текста с использованием `unicodedata`.
- `clean_text`: удаление повторяющихся ссылок и лишних пробелов с использованием `re`.
- `remove_image_links`: удаление ссылок на изображения с использованием регулярных выражений.
- `process_and_save_data`: обработка и сохранение данных из WARC-файлов.
- `convert_to_json`: преобразование очищенных данных в формат JSON.
- `main`: основной процесс, включающий вызовы всех необходимых функций и шагов.

## Установка зависимостей

Для запуска проекта необходимо установить следующие библиотеки:

```bash
pip install beautifulsoup4 lxml warcio
```

## Запуск проекта

1. Убедитесь, что все зависимости установлены.
2. Настройте пути в файле `config.json`.
3. Запустите основной скрипт:

```bash
python main.py
```

## Заключение

Этот проект предоставляет комплексное решение для обработки новостных данных, их очистки и подготовки для последующего использования в обучении языковой модели. Чат-бот, созданный на основе этой модели, сможет предоставлять актуальную информацию, ссылаясь на проверенные источники.

---

### Код

```python
import os
import hashlib
import json
from bs4 import BeautifulSoup, Comment
import unicodedata
from warcio.archiveiterator import ArchiveIterator
import re

# Загрузка конфигурации
with open('config.json', 'r') as config_file:
    config = json.load(config_file)

# Функция очистки HTML контента и извлечения ссылок
def clean_html_and_extract_links(html_content):
    soup = BeautifulSoup(html_content, 'lxml
